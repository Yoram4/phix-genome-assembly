{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome Assembly Using Overlap Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Importing the genome and simulate reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing genome file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_genome(genome_path=\"phiX174.fasta\"):\n",
    "    with open(genome_path, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if not line.startswith('>')]\n",
    "        genome = \"\".join(lines)\n",
    "    return genome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulating reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGGAGTGATGTAATGTCTAAAGGTAAAAAACGTTCTGGCGCTCGCCCTGGTCGTCCGCAGCCGTTGCGAGGTACTAAAGGCAAGCGTAAAGGCGCTCGTCTTTGGTATGTAGGTGGTCAACAATTTTAATTGCAGGGGCTTCGGCCCCTT', 'TGCCGACCCTAAATTTTTTGCCTGTTTGGTTCGCTTTGAGTCTTCTTCGGTTCCGACTACCCTCCCGACTGCCTATGATGTTTATCCTTTGAATGGTCGCCATGATGGTGGTTATTATACCGTCAAGGACTGTGTGACTATTGACGTCCT', 'ATGCTTTGCGTGACTATTTTCGTGATATTGGTCGTATGGTTCTTGCTGCCGAGGGTCGCAAGGCTAATGATTCACACGCCGACTGCTATCAGTATTTTTGTGTGCCTGAGTATGGTACAGCTAATGGCCGTCTTCATTTCCATGCGGTGC', 'CTATTATGGAAAACACCAATCTTTCCAAGCAACAGCAGGTTTCCGAGATTATGCGCCAAATGCTTACTCAAGCTCAAACGGCTGGTCAGTATTTTACCAATGACCAAATCAAAGAAATGACTCGCAAGGTTAGTGCTGAGGTTGACTTAG', 'ACAAAGTTTGGATTGCTACTGACCGCTCTCGTGCTCGTCGCTGCGTTGAGGCTTGCGTTTATGGTACGCTGGACTTTGTGGGATACCCTCGCTTTCCTGCTCCTGTTGAGTTTATTGCTGCCGTCATTGCTTATTATGTTCATCCCGTCA', 'TTTCGTATGCAGGGCGTTGAGTTCGATAATGGTGATATGTATGTTGACGGCCATAAGGCTGCTTCTGACGTTCGTGATGAGTTTGTATCTGTTACTGAGAAGTTAATGGATGAATTGGCACAATGCTACAATGTGCTCCCCCAACTTGAT', 'TGGTTGTGGCCTGTTGATGCTAAAGGTGAGCCGCTTAAAGCTACCAGTTATATGGCTGTTGGTTTCTATGTGGCTAAATACGTTAACAAAAAGTCAGATATGGACCTTGCTGCTAAAGGTCTAGGAGCTAAAGAATGGAACAACTCACTA', 'CTGGAAAGACGGTAAAGCTGATGGTATTGGCTCTAATTTGTCTAGGAAATAACCGTCAGGATTGACACCCTCCCAATTGTATGTTTTCATGCCTCCAAATCTTGGAGGCTTTTTTATGGTTCGTTCTTATTACCCTTCTGAATGTCACGC', 'CCAAATCAAAGAAATGACTCGCAAGGTTAGTGCTGAGGTTGACTTAGTTCATCAGCAAACGCAGAATCAGCGGTATGGCTCTTCTCATATTGGCGCTACTGCAAAGGATATTTCTAATGTCGTCACTGATGCTGCTTCTGGTGTGGTTGA', 'TAACACTACTGGTTATATTGACCATGCCGCTTTTCTTGGCACGATTAACCCTGATACCAATAAAATCCCTAAGCATTTGTTTCAGGGTTATTTGAATATCTATAACAACTATTTTAAAGCGCCGTGGATGCCTGACCGTACCGAGGCTAA']\n",
      "['AGGAGTGATGTAATGTCTAAAGGTAAAAAACGTTCTGGCGCTCGCCCTGGTCGTCCGCAGCCGTTGCGAGGTACTAAAGGCAAGCGTAAAGGCGCTCGTCTTTGGTATGTAGGTGGTCAACAATTTTAATTGCAGGGGCTTCGGCCCCTT', 'TGCCGACCCTAAATTTTTTGCCTGTTTGGTTCGCTTTGAGTCTTCTTCGGTTCCGACTACCCTCCCGACTGCCTATGATGTTTATCCTTTGAATGGTCGCCATGATGGTGGTTATTATACCGTCAAGGACTGTGTGACTATTGACGTCCT', 'ATGCTTTGCGTGACTATTTTCGTGATATTGGTCGTATGGTTCTTGCTGCCGAGGGTCGCAAGGCTAATGATTCACACGCCGACTGCTATCAGTATTTTTGTGTGCCTGAGTATGGTACAGCTAATGGCCGTCTTCATTTCCATGCGGTGC', 'CTATTATGGAAAGCACCAATCTTTCCAAGCAACAGCAGGTTTCCGAGATTATGCGCCAAATGCTTACTCAAGCTCAAACGGCTGGTCAGTATTTTACCAATGACCAAATCAAAGAAATGACTCGCAAGGTTAGTGCTGAGGTTGACTTAG', 'ACAAAGTTTGGATTGCTACTGACCGCTCTCGTGCTCGTCGCTGCGTTGAGGCTTGCGTTTATGGTACGCTGGACTTTGTGGGATACCCTCGCTTTCCTGCTCCTGTTGAGTTTATTGCTGCCGTCATTGCTTATTATGTTCATCCCGTCA', 'TTTCGTATGCAGGGCGTTGAGTTCGATAATGGTGATATGTATGTTGACGGCCATAAGGCTGCTTCGGACGTTTGTGATGAGTTTGTATCTGTTACTGAGAAGTTAATGGATGAATTGGCACAATGCTACAATGTGCTCCCCCAACTTGAT', 'TGGTTGTGGCCTGTTGATGCTAAAGGTGAGCCGCTTAAAGCTACCAGTTATATGGCTGTTGGTTTCTATGTGGCTAAATACGTTAACAAAAAGTCAGATATGGACCTTGCTGCTAAAGGTTTAGGAGCTAAAGAATGGAACAACTCACTA', 'CTGGAAAGACGGTAAAGCTGATGGTATTGGCTCTAATTTGTCTAGGAAATAACCGTCAGGATTGACACCCTCCCAATTGTATTTTTTCATGCCTCCAAATCTTGGAGGCTTTTTTATGGTTCGTTCTTATTACCCTTCTGAATGTCACGC', 'CCAAATCAAAGAAATGACTCGCAAGGTTAGTGCTGAGGTTGACTTAGTTCATCAGCAAACGCAGAATCAGCGGTATCGCTCTTCTCATATTGGCGCTAGTGCAAAGGATATTTCTAATGTCGTCACTGATGCTGCTTCTGGTGTGGTTGC', 'TAACACTACTGGTTATATTGACCATGCCGCTTTTCTTGGCACGATTAACCCTGATACCAATAAAATCCCTAAGCATTTGTTTCAGGGTTATTTGAATATCTATAACAAGTATTTTAAAGCGCCGTGGATGCCTGACCGTACCGAGGCTAA']\n",
      "Error rate: 0.0050\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def add_errors(reads, error_rate):\n",
    "    # error rate is between 0.001 and 0.1\n",
    "    if error_rate < 0.001:\n",
    "        return reads\n",
    "    noisy_reads = []\n",
    "    for read in reads:\n",
    "        noisy_read = \"\"\n",
    "        for base in read:\n",
    "            if random.random() < error_rate:\n",
    "                noisy_read += random.choice('ACGT'.replace(base, ''))\n",
    "            else:\n",
    "                noisy_read += base\n",
    "        noisy_reads.append(noisy_read)\n",
    "    return noisy_reads\n",
    "\n",
    "def simulate_reads(genome, num_reads, read_length, error_rate, circular = True):\n",
    "    reads = []\n",
    "    if circular:\n",
    "        genome = genome + genome[:read_length]\n",
    "    for _ in range(num_reads):\n",
    "        start = random.randint(0, len(genome))\n",
    "        read = genome[start:start + read_length]\n",
    "        reads.append(read)\n",
    "    reads = add_errors(reads, error_rate)\n",
    "    return reads\n",
    "\n",
    "# Test the functions\n",
    "reads = simulate_reads(read_genome(), 1000, 150, 0.0)\n",
    "print(reads[:10])\n",
    "noisy_reads = add_errors(reads, 0.005)\n",
    "print(noisy_reads[:10])\n",
    "error_count = sum(a != b for r, nr in zip(reads, noisy_reads) for a, b in zip(r, nr))\n",
    "total_len = sum(len(r) for r in reads)\n",
    "error_pct = error_count / total_len\n",
    "print(f\"Error rate: {error_pct:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: building an overlap graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find max overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def overlapKMP(read1, read2):\n",
    "    \"\"\"\n",
    "    Returns the length of the maximum overlap between read1 and read2\n",
    "    using the Knuth-Morris-Pratt algorithm\n",
    "    O(l = read_length) time complexity\n",
    "    \"\"\"\n",
    "    combined = read2 + \"#\" + read1\n",
    "    pi = [0] * len(combined)\n",
    "    for i in range(1, len(combined)):\n",
    "        j = pi[i - 1]\n",
    "        while j > 0 and combined[i] != combined[j]:\n",
    "            j = pi[j - 1]\n",
    "        if combined[i] == combined[j]:\n",
    "            j += 1\n",
    "        pi[i] = j\n",
    "    return pi[-1]\n",
    "\n",
    "str1 = \"ACGTACGT\"\n",
    "str2 = \"GTACGTAC\"\n",
    "print(overlapKMP(str1, str2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap graph class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverlapGraph:\n",
      "  Nodes (5): ACGAC, CCTGG, CTGGC, GTTCA, TGTCA\n",
      "  Edges (7):\n",
      "    CCTGG -> CTGGC: 4\n",
      "    GTTCA -> ACGAC: 1\n",
      "    CCTGG -> GTTCA: 1\n",
      "    ACGAC -> CCTGG: 1\n",
      "    TGTCA -> ACGAC: 1\n",
      "    CTGGC -> CCTGG: 1\n",
      "    ACGAC -> CTGGC: 1\n",
      "\n",
      "OverlapGraph:\n",
      "  Nodes (4): ACGAC, CCTGGC, GTTCA, TGTCA\n",
      "  Edges (3):\n",
      "    GTTCA -> ACGAC: 1\n",
      "    TGTCA -> ACGAC: 1\n",
      "    ACGAC -> CCTGGC: 1\n",
      "\n",
      "OverlapGraph:\n",
      "  Nodes (3): CCTGGC, GTTCACGAC, TGTCA\n",
      "  Edges (1):\n",
      "    GTTCACGAC -> CCTGGC: 1\n",
      "\n",
      "OverlapGraph:\n",
      "  Nodes (2): GTTCACGACCTGGC, TGTCA\n",
      "  Edges (0):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class OverlapGraph:\n",
    "    def __init__(self, reads, min_overlap = 1):\n",
    "        self.nodes = set()\n",
    "        self.edges = {}\n",
    "        # self.node_data = {}\n",
    "        self.min_overlap = min_overlap\n",
    "        self.build_graph(reads)\n",
    "    \n",
    "    def connect_nodes(self, node1, node2):\n",
    "        \"\"\"\n",
    "        Connects node1 to node2 if they overlap by at least min_overlap\n",
    "        O(m) time complexity\n",
    "        \"\"\"\n",
    "        overlap1 = overlapKMP(node1, node2)\n",
    "        if overlap1 >= self.min_overlap:\n",
    "            self.edges[(node1, node2)] = overlap1\n",
    "        overlap2 = overlapKMP(node2, node1)\n",
    "        if overlap2 >= self.min_overlap:\n",
    "            self.edges[(node2, node1)] = overlap2\n",
    "    \n",
    "    def add_edges(self, node):\n",
    "        \"\"\"\n",
    "        Connects the given node to all other nodes in the graph\n",
    "        O(N^2 * l) time complexity\n",
    "        \"\"\"\n",
    "        for n in self.nodes:\n",
    "            if n == node:\n",
    "                continue\n",
    "            self.connect_nodes(n, node)\n",
    "    \n",
    "    def add_node(self, node, connect = True):\n",
    "        if node not in self.nodes:\n",
    "            self.nodes.add(node)\n",
    "            if connect:\n",
    "                self.add_edges(node)\n",
    "        \n",
    "    def add_nodes(self, nodes):\n",
    "        for node in nodes:\n",
    "            self.add_node(node)\n",
    "    \n",
    "    def build_graph(self, reads):\n",
    "        self.add_nodes(reads)\n",
    "        for node in self.nodes:\n",
    "            self.add_edges(node)\n",
    "\n",
    "    def find_heaviest_edge(self):\n",
    "        \"\"\" finding heaviest edge in O(N) time \"\"\"\n",
    "        return max(self.edges, key=self.edges.get) if self.edges else None\n",
    "    \n",
    "    def remove_edge(self, edge):\n",
    "        del self.edges[edge]\n",
    "\n",
    "    def remove_edges(self, edges):\n",
    "        for edge in edges:\n",
    "            self.remove_edge(edge)\n",
    "\n",
    "    def remove_node(self, node):\n",
    "        \"\"\"\n",
    "        Removes the given node from the graph\n",
    "        \"\"\"\n",
    "        if node not in self.nodes:\n",
    "            return\n",
    "        edges_to_del = [e for e in self.edges if node in e]\n",
    "        self.remove_edges(edges_to_del)\n",
    "        self.nodes.remove(node)\n",
    "    \n",
    "    def merge_nodes(self, edge):\n",
    "        \"\"\"\n",
    "        Merges the two nodes in the given edge\n",
    "        \"\"\"\n",
    "        if edge not in self.edges:\n",
    "            return\n",
    "        n1, n2 = edge\n",
    "        overlap = self.edges[edge]\n",
    "        merged_node = n1 + n2[overlap:]\n",
    "        connected_edges = [e for e in self.edges if n1 in e or n2 in e]\n",
    "        neighbors = set(n for e in connected_edges for n in e if n != n1 and n != n2)\n",
    "        self.add_node(merged_node, connect=False)\n",
    "        # no need to add add new edges, just update the ends of the existing ones\n",
    "        for n in neighbors:\n",
    "            weight = self.edges.pop((n, n1), 0)\n",
    "            if weight:\n",
    "                self.edges[(n, merged_node)] = weight\n",
    "            weight = self.edges.pop((n2, n), 0)\n",
    "            if weight:\n",
    "                self.edges[(merged_node, n)] = weight\n",
    "            # self.connect_nodes(merged_node, n)\n",
    "        self.remove_node(n1)\n",
    "        self.remove_node(n2)\n",
    "        # return merged_node\n",
    "\n",
    "    def __str__(self):\n",
    "        result = \"OverlapGraph:\\n\"\n",
    "        result += f\"  Nodes ({len(self.nodes)}): {', '.join(sorted(self.nodes))}\\n\"\n",
    "        result += f\"  Edges ({len(self.edges)}):\\n\"\n",
    "        \n",
    "        for (n1, n2), weight in sorted(self.edges.items(), key=lambda x: x[1], reverse=True):\n",
    "            result += f\"    {n1} -> {n2}: {weight}\\n\"\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "# Test the OverlapGraph class\n",
    "reads = simulate_reads(read_genome(), 5, 5, 0.0)\n",
    "graph = OverlapGraph(reads)\n",
    "print(graph)\n",
    "while graph.edges:\n",
    "    max_edge = graph.find_heaviest_edge()\n",
    "    graph.merge_nodes(max_edge)\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: greedy assembly algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ATATGGCTGTTGGTTTCTATGTGGCTAAATACGTTAACAAAAAGTCAGATATGGACCTTGCTGCTAAAGGTCTAGGAGCTAAAGAATGGAACAACTCACTGACGCGTTGGATGAGGAGAAGTGGCTTAATATGCTTGGCACGTTCGTCAAGGACTGGTTTAGATATGAGTCACATTTTGTTCATGGTAGAGATTCTCTTGTTGACATTTTAAAAGAGCGTGGATTACTATCTGAGTCCGATGCTGTTCAACCACTAATAGGTAAGAAATCATGAGTCAAGTTACTGAACAATCCGTACGTTTCCAGACCGCTTTGGCCTCTATTAAGCTCATTCAGGCTTCTGCCGTTTTGGATTTAACCGAAGATTGAGTGTGAGGTTATAACGCCGAAGCGGTAAAAATTTTAATTTTTGCCGCTGAGGGGTTGACCAAGCGAAGCGCGGTAGGTTTTCTGCTTAGGAGTTTAATCATGTTTCAGACTTTTATTTCTCGCCATAATTCAAACTTTTTTTCTGATAAGCTGGTTCTCACTTCTGTTACTCCAGCTTCTTCGGCACCTGTTTTACAGACACCTAAAGCTACATCGTCAACGTTATATTTTGATAGTTTGACGGTTAATGCTGGTAATGGTGGTTTTCTTCATTGCATTCAGATGGATACATCTGTCATCCAACCTGCAGAGTTTTATCGCTTCCATGACGCAGAAGTTAACACTTTCGGATATTTCTGATGAGTCGAAAAATTATCTTGATAAAGCAGGAATTACTACTGCTTGTTTACGAATTAAATCGAAGTGGACTGCTGGCGGAAAATGAGAAAATTCGACCTATCCTTGCGCAGCTCGAGAAGCTCTTACTTTGCGACCTTTCGCCATCAACTAACGATTCTGTCAAAAACGCCGCTAATCAGGTTGTTTCTGTTGGTGCTGATATTGCTTTTGATGCCGACCCTAAATTTTTTGCCTGTTTGGTTCGCTTTGAGTCTTCTTCGGTTCCGACTACCCTCCCGACTGCCTATGATGTTTATCCTTTGAATGGTCGCCATGATGGTGGTTATTATACCGTCAAGGACTGTGTGACTATTGACGTCCTTCCCCGTACGCCGGGCAATAACGTTTATGTTGGTTTCATGGTTTGGTCTAACTTTACCGCTACTAAATGCCGCGGATTGGTTTCGCTGAATCAGGTTATTAAAGAGATTATTTGTCTCCAGCCACTTAAGTGAGGTGATTTATGTTTGGTGCTATTGCTGGCGGTATTGCTTCTGCTCTTGCTGGTGGCGCCATGTCTAAATTGTTTGGAGGCGGTCAAAAAGCCGCCTCCGGTGGCATTCAAGGTGATGTGCTTGCTACCGATAACAATACTGTAGGCATGGGTGATGCTGGTATTAAATCTGCCATTCAAGGCTCTAATGTTCCTAACCCTGATGAGGCCGCCCCTAGTTTTGTTTCTGGTGCTATGGCTAAAGCTGGTAAAGGACTTCTTGAAGGTACGTTGCAGGCTGGCACTTCTGCCGTGCCGCCGCGTGAAATTTCTATGAAGGATGTTTTCCGTTCTGGTGATTCGTCTAAGAAGTTTAAGATTGCTGAGGGTCAGTGGTATCGTTATGCGCCTTCGTATGTTTCTCCTGCTTATCACCTTCTTGAAGGCTTCCCATTCATTCAGGAACCGCCTTCTGGTGATTTGCAAGAACGCGTACTTATTCGCCACCATGATTATGACCAGTGTTTCCAGTCCGTTCAGTTGTTGCAGTGGAATAGTCAGGTTAAATTTAATGTGACCGTTTATCGCAATCTGCCGACCACTCGCGATTCAGCCGCAACTTCGGGATGAAAATGCTCACAATGACAAATCTGTCCACGGAGTGCTTAATCCAACTTACCAAGCTGGGTTACGACGCGACGCCGTTCAACC', 'ATATGCACAAAATGAGATGCTTGCTTATCAACAGAAGGAGTCTACTGCTCGCGTTGCGTCTATTATGGAAAACACCAATCTTTCCAAGCAACAGCAGGTTTCCGAGATTATGCGCCAAATGCTTACTCAAGCTCAAACGGCTGGTCAGTATTTTACCAATGACCAAATCAAAGAAATGACTCGCAAGGTTAGTGCTGAGGTTGACTTAGTTCATCAGCAAACGCAGAATCAGCGGTATGGCTCTTCTCATATTGGCGCTACTGCAAAGGATATTTCTAATGTCGTCACTGATGCTGCTTCTGGTGTGGTTGATATTTTTCATGGTATTGATAAAGCTCTTCATTTCCATGCGGTGCACTTTATGCGGACACTTCCTACAGGTAGCGTTGACCCTAATTTTGGTCGTCGGGTACGCAATCGCCGCCAGTTAAATAGCTTGCAAAATACGTGGCCTTATGGTTACAGTATGCCCATCGCAGTTCGCTACACGCAGGACGCTTTTTCACGTTCTGGTTGGTTGTGGCCTGTTGATAAAGGAAAGGATACTCGTGATTATCTTGCTGCTGCATTTCCTGAGCTTAATGCTTGGGAGCGTGCTGGTGCTGATGCTTCCTCTGCTGGTATGGTTGACGCCGGATTTGAGAATCAAATAACCGTCAGGATTGACACCCTCCCAATTGTATGTTTTCATGCCTCCAAATCTTGGAGGCTTTTTTATGGTTCGTTCTTATTACCCTTCTGAATGTC', 'GATTATTTTGACTTTGAGCGTATCGAGGCTCTTAAACCTGCTATTGAGGCTTGTGGCATTTCTACTCTTTCTCAATCCCCAATGCTTGGCTTCCATAAGCAGATGGATAACCGCATCAAGCTCTTGGAAGAGATTCTGTCTTTTCGTATGCAGGGCGTTGAGTTCGATAATTACGTGCGGAAGGAGTGATGTAATGTCTAAAGGTAAAAAACGTTCTGGCGCTCGCCCTGGTCGTCCGCAGCCGTTGCGAGGTACTAAAGGCAAGCGTAAAGGCGCTCGTCTTTGGTATGTAGGTGGTCAACAATTTTAATTGCAGGGGCTTCGGCCCCTTACTTGAGGATAAATTATGTCTAATATTCAAACTGGCGCCGAGCGTATGCCGCATGACCTTTCCCATCTTGGCTTCCTTGCTGGTCAGATTGGTCGTCTTATTACCATTTCAACTACTCCGGTTATCGCTGGCGACTCCTTCGAGATGGACGCCGTTGGCGCTCTCCGTCTTTCTCCATTGCGTCGTGGCCTTGCTATTGACTCTACTGTAGACATTTTTACTTTTTATGTCCCTCATCGTCACGTTTATGGTGAACAGTGGATTAAGTTCATGAAGGATGGTGTTAATGCCACTCCTCTCCCGACTGTTAACACTACTGGTTATATTGACCATGCCGCTTTTCTTGGCACGATTAACCCTGATACCAATAAAATCCCTAAGCATTTGTTTCAGGGTTATTTGAATATCTATAACAACTATTTTAAAGCGCCGTGGATGCCTGACCGTACCGAGGCTAACCCTAATGAGCTTAATCAAGATGATGCTCGTTATGGTTTCCGTTGCTGCCATCTCAAAAACATTTGGACTGCTCCGCTTCCTCCTGAGACTGAGCTTTCTCGCCAAATGACGACTTCTACCACATCTATTGACATTATGGGTCTGCAAGCTGCTTATGCTAATTTGCATACTGACCAAGAACGTGATTACTTCATGCAGCGTTACCATGATGTTATTTCTTCATTTGGAGGTAAAACCTCTTATGACGCTGACAACCGTCCTTTACTTGTCATGCGCTCTAATCTCTGGGCATCTGGCTATGATGTTGATGGAACTGACCAAACGTCGTTAGGCCAGTTTTCTGGTCGTGTTCAACAGACCTATAAACATTCTGTGCCGCGTTTCTTTGTTCCTGAGCATGGCACTATGTTTACTCTTGCGCTTGTTCGATTAGAGGCGTTTTATGATAATCCCAATGCTTTGCGTGACTATTTTCGTGATATTGGTCGTATGGTTCTTGCTGCCGAGGGTCGCAAGGCTAATGATTCACACGCCGACTGCTATCAGTATTTTTCTGACGAGTAACAAAGTTTGGATTGCTACTGACCGCTCTCGTGCTCGTCGCTGCGTTGAGGCTTGCGTTTATGGTACGCTGGACTTTGTGGGATACCCTCGCTTTCCTGCTCCTGTTGAGTTTATTGCTGCCGTCATTGCTTATTATGTTCATCCCGTCAACATTCAAACGGCCTGTCTCATCATGGAAGGCGCTGAATTTACGGAAAACATTATTAATGGCGTCGAGCGTCCGGTTAAAGCCGCTGAATTGTTGGCACAATGCTACAATGTGCTCCCCCAACTTGATATTAATAACACTATAGACCACCGCCCCGAAGGGGACGAAAAATGGTTTTTAGAGAACGAGAAGACGGTTACGCAGTTTTGCCGCAAGCTGGCTGCTGAACGCCCTCTTAAGGATATTCGCGATGAGTATAATTACCCCAAAAAGAAAGGTATTAAGGATGAGTGTTCAAGATTGCTGGAGGCCTCCACTATGAAATCGCGTAGAGGCTTTGCTATTCAGCGTTTGATGAATGCAATGCGACAGGCTCATGCTGATGGTTGGTTTATCGTTTTTGACACTCTCACGTTGGC']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def greedy_scs(reads, min_overlap = 1):\n",
    "    graph = OverlapGraph(reads, min_overlap)\n",
    "    while graph.edges:\n",
    "        max_edge = graph.find_heaviest_edge()\n",
    "        graph.merge_nodes(max_edge)\n",
    "    return list(graph.nodes)\n",
    "\n",
    "reads = simulate_reads(read_genome(), 100, 100, 0.0)\n",
    "scs = greedy_scs(reads)\n",
    "print(scs)\n",
    "print(len(scs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_assembly(contigs, original_genome, circular=True):\n",
    "    if circular:\n",
    "        max_contig_len = max(len(c) for c in contigs) if contigs else 0\n",
    "        working_genome = original_genome + original_genome[:max_contig_len]\n",
    "    else:\n",
    "        working_genome = original_genome\n",
    "    \n",
    "    metrics = {\n",
    "        'genome_length': len(original_genome),\n",
    "        'assembly_length': sum(len(c) for c in contigs),\n",
    "        'contigs_count': len(contigs),\n",
    "        'aligned_bases': 0,\n",
    "        'mismatches': 0,\n",
    "        'unaligned_contigs': 0,\n",
    "        'positions_covered': set(),\n",
    "    }\n",
    "    \n",
    "    for contig in contigs:\n",
    "        best_pos = find_best_alignment(contig, working_genome)\n",
    "        \n",
    "        if best_pos['position'] == -1:\n",
    "            metrics['unaligned_contigs'] += 1\n",
    "            continue\n",
    "        \n",
    "        metrics['aligned_bases'] += best_pos['aligned_length']\n",
    "        metrics['mismatches'] += best_pos['mismatches']\n",
    "        \n",
    "        # track positions covered by the contig\n",
    "        start = best_pos['position']\n",
    "        end = start + len(contig)\n",
    "        \n",
    "        for pos in range(start, end):\n",
    "            # map back to original genome coordinates\n",
    "            original_pos = pos % len(original_genome)\n",
    "            metrics['positions_covered'].add(original_pos)\n",
    "    \n",
    "    metrics['genome_coverage'] = len(metrics['positions_covered']) / len(original_genome)\n",
    "    if metrics['aligned_bases'] > 0:\n",
    "        metrics['sequence_identity'] = 1 - (metrics['mismatches'] / metrics['aligned_bases'])\n",
    "    else:\n",
    "        metrics['sequence_identity'] = 0\n",
    "    \n",
    "    # N50\n",
    "    sorted_contigs = sorted(contigs, key=len, reverse=True)\n",
    "    cumulative_length = 0\n",
    "    n50 = 0\n",
    "    l50 = 0\n",
    "    \n",
    "    for i, contig in enumerate(sorted_contigs):\n",
    "        cumulative_length += len(contig)\n",
    "        if cumulative_length >= metrics['assembly_length'] / 2:\n",
    "            n50 = len(contig)\n",
    "            l50 = i + 1\n",
    "            break\n",
    "    \n",
    "    metrics['N50'] = n50\n",
    "    metrics['L50'] = l50\n",
    "    \n",
    "    # convert positions_covered to a count\n",
    "    metrics['positions_covered'] = len(metrics['positions_covered'])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def find_best_alignment(contig, genome, k=10, max_positions=100):\n",
    "    if len(contig) <= k:\n",
    "        return find_best_alignment_exhaustive(contig, genome)\n",
    "    \n",
    "    # building k-mer index for the genome\n",
    "    kmer_positions = {}\n",
    "    for i in range(len(genome) - k + 1):\n",
    "        kmer = genome[i:i+k]\n",
    "        if kmer not in kmer_positions:\n",
    "            kmer_positions[kmer] = []\n",
    "        kmer_positions[kmer].append(i)\n",
    "    \n",
    "    # searching for the best alignment\n",
    "    position_counts = {}\n",
    "    for i in range(len(contig) - k + 1):\n",
    "        kmer = contig[i:i+k]\n",
    "        if kmer in kmer_positions:\n",
    "            for pos in kmer_positions[kmer]:\n",
    "                # checking all possible positions\n",
    "                genome_start = pos - i\n",
    "                if genome_start >= 0 and genome_start + len(contig) <= len(genome):\n",
    "                    position_counts[genome_start] = position_counts.get(genome_start, 0) + 1\n",
    "    \n",
    "    # sorting candidate positions by count\n",
    "    candidate_positions = sorted(position_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # finding the best alignment among top candidates\n",
    "    best_position = -1\n",
    "    best_score = -float('inf')\n",
    "    best_mismatches = len(contig)\n",
    "    \n",
    "    for position, _ in candidate_positions[:max_positions]:\n",
    "        if position + len(contig) > len(genome):\n",
    "            continue\n",
    "            \n",
    "        mismatches = 0\n",
    "        for j in range(len(contig)):\n",
    "            if contig[j] != genome[position + j]:\n",
    "                mismatches += 1\n",
    "        \n",
    "        score = len(contig) - mismatches\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_position = position\n",
    "            best_mismatches = mismatches\n",
    "    \n",
    "    return {\n",
    "        'position': best_position,\n",
    "        'aligned_length': len(contig),\n",
    "        'mismatches': best_mismatches,\n",
    "        'score': best_score\n",
    "    }\n",
    "\n",
    "def find_best_alignment_exhaustive(contig, genome):\n",
    "    \"\"\"\n",
    "    Finds the best alignment of a contig in the genome using an exhaustive search.\n",
    "    O(n * m) time complexity.\n",
    "    \"\"\"\n",
    "    best_position = -1\n",
    "    best_score = -float('inf')\n",
    "    best_mismatches = len(contig)\n",
    "    \n",
    "    for i in range(len(genome) - len(contig) + 1):\n",
    "        mismatches = 0\n",
    "        for j in range(len(contig)):\n",
    "            if contig[j] != genome[i + j]:\n",
    "                mismatches += 1\n",
    "        \n",
    "        score = len(contig) - mismatches\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_position = i\n",
    "            best_mismatches = mismatches\n",
    "    \n",
    "    return {\n",
    "        'position': best_position,\n",
    "        'aligned_length': len(contig),\n",
    "        'mismatches': best_mismatches,\n",
    "        'score': best_score\n",
    "    }\n",
    "\n",
    "def detect_chimeric_contigs(contigs, original_genome, circular=True):\n",
    "    \"\"\"\n",
    "    Detects chimeric contigs by checking for unexpected gaps between the two halves of the contig.\n",
    "    returns: list of indices of chimeric contigs\n",
    "    \"\"\"\n",
    "    if circular:\n",
    "        max_contig_len = max(len(c) for c in contigs) if contigs else 0\n",
    "        working_genome = original_genome + original_genome[:max_contig_len]\n",
    "    else:\n",
    "        working_genome = original_genome\n",
    "    \n",
    "    chimeric_contigs = []\n",
    "    \n",
    "    for i, contig in enumerate(contigs):\n",
    "        if len(contig) < 20:\n",
    "            continue\n",
    "            \n",
    "        first_half = contig[:len(contig)//2]\n",
    "        second_half = contig[len(contig)//2:]\n",
    "        \n",
    "        align1 = find_best_alignment(first_half, working_genome)\n",
    "        align2 = find_best_alignment(second_half, working_genome)\n",
    "        \n",
    "        if align1['position'] != -1 and align2['position'] != -1:\n",
    "            expected_pos2 = align1['position'] + len(first_half)\n",
    "            actual_pos2 = align2['position']\n",
    "            \n",
    "            # calculate distance between the two halves\n",
    "            if circular:\n",
    "                distance = min(\n",
    "                    abs(actual_pos2 - expected_pos2),\n",
    "                    abs(actual_pos2 - expected_pos2 + len(original_genome)),\n",
    "                    abs(actual_pos2 - expected_pos2 - len(original_genome))\n",
    "                )\n",
    "            else:\n",
    "                distance = abs(actual_pos2 - expected_pos2)\n",
    "            \n",
    "            if distance > 10:\n",
    "                chimeric_contigs.append(i)\n",
    "    \n",
    "    return chimeric_contigs\n",
    "\n",
    "# def visualize_genome_coverage(contigs, original_genome, circular=True):\n",
    "#     \"\"\"\n",
    "#     Visualizes the coverage of the genome by the assembled contigs.\n",
    "#     Returns a string with a text-based visualization.\n",
    "#     \"\"\"\n",
    "#     coverage = [0] * len(original_genome)\n",
    "    \n",
    "#     if circular:\n",
    "#         max_contig_len = max(len(c) for c in contigs) if contigs else 0\n",
    "#         working_genome = original_genome + original_genome[:max_contig_len]\n",
    "#     else:\n",
    "#         working_genome = original_genome\n",
    "    \n",
    "#     for contig in contigs:\n",
    "#         alignment = find_best_alignment(contig, working_genome)\n",
    "#         if alignment['position'] == -1:\n",
    "#             continue\n",
    "        \n",
    "#         start_pos = alignment['position']\n",
    "#         end_pos = start_pos + len(contig)\n",
    "        \n",
    "#         for pos in range(start_pos, end_pos):\n",
    "#             # map back to original genome coordinates\n",
    "#             original_pos = pos % len(original_genome)\n",
    "#             coverage[original_pos] += 1\n",
    "    \n",
    "#     max_coverage = max(coverage) if coverage else 0\n",
    "#     visualization = [\"Genome coverage:\"]\n",
    "#     # visualization.append(\"Position | Coverage\")\n",
    "#     visualization.append(\"position\" + \" \" * 5 + \"coverage\")\n",
    "#     visualization.append(\"-\" * 30)\n",
    "    \n",
    "#     chunk_size = max(1, len(original_genome) // 50)\n",
    "    \n",
    "#     for i in range(0, len(original_genome), chunk_size):\n",
    "#         end = min(i + chunk_size, len(original_genome))\n",
    "#         avg_coverage = sum(coverage[i:end]) / (end - i)\n",
    "#         bar = \"#\" * int(avg_coverage * 20 / max_coverage) if max_coverage > 0 else \"\"\n",
    "#         visualization.append(f\"{i:8d} - {end-1:8d} | {avg_coverage:5.1f} {bar}\")\n",
    "    \n",
    "#     return \"\\n\".join(visualization)\n",
    "\n",
    "def test_assembly(reads, original_genome, min_overlap=20, circular=True):\n",
    "    \"\"\"\n",
    "    returns tuple: (metrics, assembled_contigs)\n",
    "    \"\"\"\n",
    "    print(\"Assembling genome...\")\n",
    "    assembled_contigs = greedy_scs(reads, min_overlap)\n",
    "    \n",
    "    print(\"Evaluating assembly...\")\n",
    "    metrics = evaluate_assembly(assembled_contigs, original_genome, circular)\n",
    "    # Detect chimeric contigs\n",
    "    chimeric_indices = detect_chimeric_contigs(assembled_contigs, original_genome, circular)\n",
    "    metrics['chimeric_contigs'] = len(chimeric_indices)\n",
    "    # Visualize genome coverage\n",
    "    # coverage_viz = visualize_genome_coverage(assembled_contigs, original_genome, circular)\n",
    "    \n",
    "    print(f\"=== Assembly Evaluation ===\")\n",
    "    print(f\"Original genome length: {metrics['genome_length']} bp\")\n",
    "    print(f\"Assembly length: {metrics['assembly_length']} bp\")\n",
    "    print(f\"Number of contigs: {metrics['contigs_count']}\")\n",
    "    print(f\"N50: {metrics['N50']} bp\")\n",
    "    print(f\"L50: {metrics['L50']}\")\n",
    "    print(f\"Genome coverage: {metrics['genome_coverage']*100:.2f}%\")\n",
    "    print(f\"Sequence identity: {metrics['sequence_identity']*100:.2f}%\")\n",
    "    print(f\"Unaligned contigs: {metrics['unaligned_contigs']}\")\n",
    "    print(f\"Chimeric contigs: {metrics['chimeric_contigs']}\")\n",
    "    # print(\"\\n\" + coverage_viz)\n",
    "    \n",
    "    return metrics, assembled_contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1/1: num_reads=300, read_length=150, error_rate=0.01, min_overlap=10\n",
      "Assembling genome...\n",
      "Evaluating assembly...\n",
      "=== Assembly Evaluation ===\n",
      "Original genome length: 5386 bp\n",
      "Assembly length: 32275 bp\n",
      "Number of contigs: 129\n",
      "N50: 276 bp\n",
      "L50: 38\n",
      "Genome coverage: 100.00%\n",
      "Sequence identity: 98.71%\n",
      "Unaligned contigs: 0\n",
      "Chimeric contigs: 0\n",
      "\n",
      "All results have been successfully saved to file: parameter_sweep_results_20250310_004144.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def run_parameter_sweep(genome, num_reads_list, read_length_list, error_rate_list, min_overlap_list, circular=True, output_format=\"csv\"):\n",
    "    all_results = []\n",
    "    \n",
    "    # Counter to track progress\n",
    "    total_runs = len(num_reads_list) * len(read_length_list) * len(error_rate_list) * len(min_overlap_list)\n",
    "    current_run = 0\n",
    "    \n",
    "    for n in num_reads_list:\n",
    "        for l in read_length_list:\n",
    "            for er in error_rate_list:\n",
    "                for o in min_overlap_list:\n",
    "                    current_run += 1\n",
    "                    print(f\"\\nRun {current_run}/{total_runs}: num_reads={n}, read_length={l}, error_rate={er}, min_overlap={o}\")\n",
    "                    \n",
    "                    reads = simulate_reads(genome, n, l, er, circular=circular)\n",
    "                    \n",
    "                    metrics, contigs = test_assembly(reads, genome, o, circular=circular)\n",
    "                    \n",
    "                    run_metrics = {\n",
    "                        'num_reads': n,\n",
    "                        'read_length': l,\n",
    "                        'error_rate': er,\n",
    "                        'min_overlap': o,\n",
    "                        'total_reads_length': n * l,\n",
    "                        'coverage': (n * l) / len(genome),\n",
    "                    }\n",
    "                    \n",
    "                    # Add all metrics\n",
    "                    for key, value in metrics.items():\n",
    "                        if not isinstance(value, (set, list, dict)):\n",
    "                            run_metrics[key] = value\n",
    "                    \n",
    "                    all_results.append(run_metrics)\n",
    "    \n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save results to a file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    main_file = f\"parameter_sweep_results_{timestamp}.csv\"\n",
    "    results_df.to_csv(main_file, index=False)\n",
    "    \n",
    "    print(f\"\\nAll results have been successfully saved to file: {main_file}\")\n",
    "    return main_file\n",
    "    \n",
    "# Example usage:\n",
    "num_reads = [300]\n",
    "read_length = [150]\n",
    "error_rate = [0.01]\n",
    "min_overlap = [10]\n",
    "\n",
    "genome = read_genome()\n",
    "\n",
    "# Use automatic format - will choose CSV if openpyxl is not installed\n",
    "results_path = run_parameter_sweep(genome, num_reads, read_length, error_rate, min_overlap, circular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1/1: num_reads=700, read_length=150, error_rate=0.0, min_overlap=10\n",
      "Assembling genome...\n",
      "Evaluating assembly...\n",
      "=== Assembly Evaluation ===\n",
      "Original genome length: 5386 bp\n",
      "Assembly length: 5487 bp\n",
      "Number of contigs: 1\n",
      "N50: 5487 bp\n",
      "L50: 1\n",
      "Genome coverage: 100.00%\n",
      "Sequence identity: 100.00%\n",
      "Unaligned contigs: 0\n",
      "Chimeric contigs: 0\n",
      "\n",
      "All results have been successfully saved to file: parameter_sweep_results_20250310_003627.csv\n"
     ]
    }
   ],
   "source": [
    "num_reads = [300, 500, 700, 900, 1100]\n",
    "read_length = [100, 150, 200, 250]\n",
    "error_rate = [0.0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "min_overlap = [1, 10, 20, 30]\n",
    "\n",
    "genome = read_genome()\n",
    "excel_file = run_parameter_sweep(genome, num_reads, read_length, error_rate, min_overlap, circular=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: N50 and Contiguity vs. N and l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"experiments_results.csv\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "fig.suptitle('N50 and Contiguity vs. Number of Reads and Read Length', fontsize=16)\n",
    "\n",
    "# Filter for error rate 0 to focus on the effect of reads and length\n",
    "filtered_data = data[data[\"Error Rate\"] == 0]\n",
    "\n",
    "# Plot 1: N50 vs Number of Reads\n",
    "read_counts = sorted(filtered_data[\"Number of Reads\"].unique())\n",
    "n50_by_reads = [filtered_data[filtered_data[\"Number of Reads\"] == n][\"N50\"].mean() for n in read_counts]\n",
    "\n",
    "axs[0, 0].plot(read_counts, n50_by_reads, 'o-', color='blue', linewidth=2, markersize=8)\n",
    "axs[0, 0].set_title('N50 vs Number of Reads', fontsize=14)\n",
    "axs[0, 0].set_xlabel('Number of Reads', fontsize=12)\n",
    "axs[0, 0].set_ylabel('Average N50', fontsize=12)\n",
    "axs[0, 0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot 2: Number of Contigs vs Number of Reads\n",
    "contigs_by_reads = [filtered_data[filtered_data[\"Number of Reads\"] == n][\"Number of contigs\"].mean() for n in read_counts]\n",
    "\n",
    "axs[0, 1].plot(read_counts, contigs_by_reads, 'o-', color='red', linewidth=2, markersize=8)\n",
    "axs[0, 1].set_title('Number of Contigs vs Number of Reads', fontsize=14)\n",
    "axs[0, 1].set_xlabel('Number of Reads', fontsize=12)\n",
    "axs[0, 1].set_ylabel('Average Number of Contigs', fontsize=12)\n",
    "axs[0, 1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot 3: N50 vs Read Length\n",
    "read_lengths = sorted(filtered_data[\"Read Length\"].unique())\n",
    "n50_by_length = [filtered_data[filtered_data[\"Read Length\"] == l][\"N50\"].mean() for l in read_lengths]\n",
    "\n",
    "axs[1, 0].plot(read_lengths, n50_by_length, 'o-', color='green', linewidth=2, markersize=8)\n",
    "axs[1, 0].set_title('N50 vs Read Length', fontsize=14)\n",
    "axs[1, 0].set_xlabel('Read Length', fontsize=12)\n",
    "axs[1, 0].set_ylabel('Average N50', fontsize=12)\n",
    "axs[1, 0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot 4: Number of Contigs vs Read Length\n",
    "contigs_by_length = [filtered_data[filtered_data[\"Read Length\"] == l][\"Number of contigs\"].mean() for l in read_lengths]\n",
    "\n",
    "axs[1, 1].plot(read_lengths, contigs_by_length, 'o-', color='purple', linewidth=2, markersize=8)\n",
    "axs[1, 1].set_title('Number of Contigs vs Read Length', fontsize=14)\n",
    "axs[1, 1].set_xlabel('Read Length', fontsize=12)\n",
    "axs[1, 1].set_ylabel('Average Number of Contigs', fontsize=12)\n",
    "axs[1, 1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# value labels to the points\n",
    "for i, n in enumerate(read_counts):\n",
    "    axs[0, 0].annotate(f\"{n50_by_reads[i]:.1f}\", (n, n50_by_reads[i]), \n",
    "                      textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "    axs[0, 1].annotate(f\"{contigs_by_reads[i]:.1f}\", (n, contigs_by_reads[i]), \n",
    "                      textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "for i, l in enumerate(read_lengths):\n",
    "    axs[1, 0].annotate(f\"{n50_by_length[i]:.1f}\", (l, n50_by_length[i]), \n",
    "                      textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "    axs[1, 1].annotate(f\"{contigs_by_length[i]:.1f}\", (l, contigs_by_length[i]), \n",
    "                      textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for the suptitle\n",
    "plt.savefig(\"n50_contigs_vs_reads_length.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2: Number of Contigs vs. Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"experiments_results.csv\")\n",
    "\n",
    "# group by error rate and calculate the average number of contigs\n",
    "grouped_data = data.groupby(\"Error Rate\")[\"Number of contigs\"].mean().reset_index()\n",
    "\n",
    "# simple line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(grouped_data[\"Error Rate\"], grouped_data[\"Number of contigs\"], \n",
    "         'o-', color='blue', linewidth=2, markersize=8)\n",
    "\n",
    "# labels and title\n",
    "plt.title(\"Average Number of Contigs vs Error Rate\", fontsize=14)\n",
    "plt.xlabel(\"Error Rate\", fontsize=12)\n",
    "plt.ylabel(\"Average Number of Contigs\", fontsize=12)\n",
    "\n",
    "# value labels on each point\n",
    "for x, y in zip(grouped_data[\"Error Rate\"], grouped_data[\"Number of contigs\"]):\n",
    "    plt.text(x, y + 15, f\"{y:.1f}\", ha='center', fontsize=10)\n",
    "\n",
    "# grid lines\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"simple_contigs_vs_error_rate.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3: Sequence Identity by Error Rate and Minimum Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"experiments_results.csv\")\n",
    "\n",
    "heatmap_data = data.groupby([\"Error Rate\", \"Min Overlap\"])[\"Sequence identity\"].mean().reset_index()\n",
    "pivot_data = heatmap_data.pivot(\"Error Rate\", \"Min Overlap\", \"Sequence identity\")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# values below 95% in red tones and above 95% in blue tones\n",
    "center = 95\n",
    "vmin = pivot_data.min().min()\n",
    "vmax = 100  # Maximum possible sequence identity\n",
    "\n",
    "ax = sns.heatmap(pivot_data, annot=True, fmt=\".1f\", \n",
    "                cmap=\"coolwarm_r\", center=center,\n",
    "                vmin=vmin, vmax=vmax,\n",
    "                linewidth=0.5, \n",
    "                cbar_kws={'label': 'Sequence Identity (%)'})\n",
    "\n",
    "plt.title(\"Sequence Identity by Error Rate and Minimum Overlap\", fontsize=16)\n",
    "plt.xlabel(\"Minimum Overlap\", fontsize=14)\n",
    "plt.ylabel(\"Error Rate\", fontsize=14)\n",
    "\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_visible(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sequence_identity_heatmap_centered.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
